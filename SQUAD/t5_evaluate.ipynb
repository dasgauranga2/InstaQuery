{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from transformers import T5Model,T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', '▁world', '▁how', '▁are', '▁you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello world how are you?')\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8774, 296, 149, 33, 25, 58]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.pad_token\n",
    "eos_token = tokenizer.eos_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 2\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['t5-small']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauranga/anaconda3/envs/pt/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SRC = Field(batch_first = True,\n",
    "          use_vocab = False,\n",
    "          tokenize = tokenize_and_cut,\n",
    "          preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "          init_token = init_token_idx,\n",
    "          eos_token = eos_token_idx,\n",
    "          pad_token = pad_token_idx,\n",
    "          unk_token = unk_token_idx)\n",
    "\n",
    "TRG = Field(batch_first = True,\n",
    "          use_vocab = False,\n",
    "          tokenize = tokenize_and_cut,\n",
    "          preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "          init_token = init_token_idx,\n",
    "          eos_token = eos_token_idx,\n",
    "          pad_token = pad_token_idx,\n",
    "          unk_token = unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('src', SRC), ('trg', TRG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauranga/anaconda3/envs/pt/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/gauranga/anaconda3/envs/pt/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data = data.TabularDataset.splits(\n",
    "                path = '',\n",
    "                train = 'squad.csv',\n",
    "                format = 'csv',\n",
    "                fields = fields,\n",
    "                skip_header = True)\n",
    "\n",
    "train_data , valid_data = train_data[0].split(split_ratio=0.98,\n",
    "                                             random_state = random.seed(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57226\n",
      "1168\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.examples))\n",
    "print(len(valid_data.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': [2625, 3, 10, 8, 9398, 13, 4353, 7041, 63, 54, 43, 359, 11041, 11, 569, 7702, 5, 778, 18677, 53, 5234, 33, 1086, 5065, 49, 11, 6879, 145, 70, 803, 5, 822, 3, 10, 33, 778, 42, 1480, 18677, 53, 5234, 2389, 5065, 49, 11, 6879, 145, 70, 803, 58], 'trg': [778]}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[25000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁context', '▁', ':', '▁one', '▁way', '▁of', '▁', 'proving', '▁that', '▁', 'a', '▁given', '▁disease', '▁is', '▁\"', 'in', 'fect', 'ious', '\",', '▁is', '▁to', '▁satisfy', '▁', 'koch', \"'\", 's', '▁post', 'ulate', 's', '▁(', 'first', '▁proposed', '▁by', '▁', 'rob', 'er', 't', '▁', 'koch', '),', '▁which', '▁demands', '▁that', '▁the', '▁infectious', '▁agent', '▁be', '▁identified', '▁only', '▁in', '▁patients', '▁and', '▁not', '▁in', '▁healthy', '▁controls', ',', '▁and', '▁that', '▁patients', '▁who', '▁contract', '▁the', '▁agent', '▁also', '▁develop', '▁the', '▁disease', '.', '▁question', '▁', ':', '▁what', '▁must', '▁an', '▁infectious', '▁agent', '▁only', '▁be', '▁identified', '▁in', '▁to', '▁satisfy', '▁the', '▁first', '▁of', '▁', 'koch', \"'\", 's', '▁post', 'ulate', 's', '?']\n",
      "['▁patients', '▁and', '▁not', '▁in', '▁healthy', '▁controls']\n"
     ]
    }
   ],
   "source": [
    "src_tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[2000])['src'])\n",
    "trg_tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[2000])['trg'])\n",
    "\n",
    "print(src_tokens)\n",
    "print(trg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauranga/anaconda3/envs/pt/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "                                 (train_data, valid_data), \n",
    "                                 batch_size = BATCH_SIZE,\n",
    "                                 device = device,\n",
    "                                 sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.t5 = T5Model.from_pretrained('t5-small')\n",
    "        \n",
    "        self.out = nn.Linear(self.t5.config.to_dict()['d_model'],\n",
    "                             self.t5.config.to_dict()['vocab_size'])\n",
    "                \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded = self.t5(input_ids=src,decoder_input_ids=trg) \n",
    "        \n",
    "        output = self.out(embedded[0])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = T5Network().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 76,988,544 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT ALL MODEL WEIGHTS AND BIASES TO HALF PRECISION\n",
    "# MODEL SIZE WILL REDUCE\n",
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('t5_qa_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence2(sentence, eval_model, device, max_len = 50):\n",
    "    \n",
    "    eval_model.eval()\n",
    "\n",
    "    src_indexes = [init_token_idx] + sentence + [eos_token_idx]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [init_token_idx]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = eval_model(src_tensor, trg_tensor)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == eos_token_idx:\n",
    "            break\n",
    "\n",
    "    return trg_indexes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC : ▁context▁:▁nasser▁played▁a▁significant▁part▁in▁the▁strengthening▁of▁african▁solidarity▁in▁the▁late▁1950s▁and▁early▁1960s,▁although▁his▁continental▁leadership▁role▁had▁increasingly▁passed▁to▁algeria▁since▁1962.▁during▁this▁period,▁nasser▁made▁egypt▁a▁refuge▁for▁anti-colonial▁leaders▁from▁several▁african▁countries▁and▁allowed▁the▁broadcast▁of▁anti-colonial▁propaganda▁from▁cairo.▁beginning▁in▁1958,▁nasser▁had▁a▁key▁role▁in▁the▁discussions▁among▁african▁leaders▁that▁led▁to▁the▁establishment▁of▁the▁organisation▁of▁african▁unity▁(oau)▁in▁1963.▁question▁:▁what▁continent▁did▁nasser▁help▁to▁attain▁political▁stability?\n",
      "TRG : ▁african\n",
      "PRED : ▁african</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁university▁houses▁the▁following▁public▁broadcasting▁stations:▁kjhk,▁a▁student-run▁campus▁radio▁station,▁kujh-lp,▁an▁independent▁station▁that▁primarily▁broadcasts▁public▁affairs▁programs,▁and▁kanu,▁the▁npr-affiliated▁radio▁station.▁kansas▁public▁radio▁station▁kanu▁was▁one▁of▁the▁first▁public▁radio▁stations▁in▁the▁nation.▁kjhk,▁the▁campus▁radio▁has▁roots▁back▁to▁1952▁and▁is▁completely▁run▁by▁students.▁question▁:▁what▁are▁the▁call▁letters▁of▁the▁national▁public▁radio▁affiliate▁that▁broadcasts▁from▁ku?\n",
      "TRG : ▁kanu\n",
      "PRED : ▁kanu</s>\n",
      "\n",
      "SRC : ▁context▁:▁wide-ringed▁wood▁is▁often▁called▁\"second-growth\",▁because▁the▁growth▁of▁the▁young▁timber▁in▁open▁stands▁after▁the▁old▁trees▁have▁been▁removed▁is▁more▁rapid▁than▁in▁trees▁in▁a▁closed▁forest,▁and▁in▁the▁manufacture▁of▁articles▁where▁strength▁is▁an▁important▁consideration▁such▁\"second-growth\"▁hardwood▁material▁is▁preferred.▁question▁:▁what▁term▁is▁sometimes▁used▁for▁wood▁with▁wide▁rings?\n",
      "TRG : ▁second-growth\n",
      "PRED : ▁second-growth</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁rise▁of▁hitler▁and▁other▁dictators▁in▁the▁1930s▁forced▁numerous▁catholic▁intellectuals▁to▁flee▁europe;▁president▁john▁o'hara▁brought▁many▁to▁notre▁dame.▁from▁germany▁came▁anton-hermann▁chroust▁(1907–1982)▁in▁classics▁and▁law,▁and▁waldemar▁gurian▁a▁german▁catholic▁intellectual▁of▁jewish▁descent.▁question▁:▁what▁field▁of▁study▁did▁anton-hermann▁chroust▁specialize▁in?\n",
      "TRG : ▁classics▁and▁law\n",
      "PRED : ▁classics▁and▁law</s>\n",
      "\n",
      "SRC : ▁context▁:▁in▁1952,▁following▁a▁referendum,▁baden,▁württemberg-baden,▁and▁württemberg-hohenzollern▁merged▁into▁baden-württemberg.▁question▁:▁which▁city▁did▁baden,▁württemberg-baden,▁and▁württemberg-hohenzollern▁merge▁into?\n",
      "TRG : ▁baden-württemberg\n",
      "PRED : ▁baden-württemberg</s>\n",
      "\n",
      "SRC : ▁context▁:▁some▁rock▁formations▁in▁the▁path▁of▁a▁glacier▁are▁sculpted▁into▁small▁hills▁called▁roche▁moutonnée,▁or▁\"sheepback\"▁rock.▁roche▁moutonnée▁are▁elongated,▁rounded,▁and▁asymmetrical▁bedrock▁knobs▁that▁can▁be▁produced▁by▁glacier▁erosion.▁question▁:▁what▁are▁roche▁moutonnee?\n",
      "TRG : ▁elongated,▁rounded,▁and▁asymmetrical▁bedrock▁knobs▁that▁can▁be▁produced▁by▁glacier▁erosion\n",
      "PRED : ▁elongated,▁rounded,▁and▁asymmetrical▁bedrock▁knobs▁that▁can▁be▁produced▁by▁glacier▁erosion</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁upgrade▁addressed▁a▁number▁of▁criticisms▁faced▁by▁windows▁8▁upon▁its▁release,▁with▁additional▁customization▁options▁for▁the▁start▁screen,▁the▁restoration▁of▁a▁visible▁start▁button▁on▁the▁desktop,▁the▁ability▁to▁snap▁up▁to▁four▁apps▁on▁a▁single▁display,▁and▁the▁ability▁to▁boot▁to▁the▁desktop▁instead▁of▁the▁start▁screen.▁question▁:▁how▁many▁apps▁did▁the▁windows▁8.1▁update▁allow▁to▁be▁snapped▁onto▁a▁signular▁display?\n",
      "TRG : ▁up▁to▁four\n",
      "PRED : ▁up▁to▁four</s>\n",
      "\n",
      "SRC : ▁context▁:▁on▁12▁july▁2007,▁european▁court▁of▁human▁rights▁when▁dismissing▁the▁appeal▁by▁nikola▁jorgi<unk>▁against▁his▁conviction▁for▁genocide▁by▁a▁german▁court▁(jorgic▁v.▁germany)▁noted▁that▁the▁german▁courts▁wider▁interpretation▁of▁genocide▁has▁since▁been▁rejected▁by▁international▁courts▁considering▁similar▁cases.▁question▁:▁in▁jorgic▁v.▁germany,▁what▁about▁the▁german▁courts▁was▁later▁rejected▁by▁international▁courts▁hearing▁similar▁cases?\n",
      "TRG : ▁wider▁interpretation▁of▁genocide\n",
      "PRED : ▁wider▁interpretation▁of▁genocide</s>\n",
      "\n",
      "SRC : ▁context▁:▁it▁is▁estimated▁that▁there▁are▁around▁100▁elephants▁left▁in▁eritrea,▁the▁most▁northerly▁of▁east▁africa's▁elephants.▁the▁endangered▁african▁wild▁dog▁(lycaon▁pictus)▁was▁previously▁found▁in▁eritrea,▁but▁is▁now▁deemed▁extirpated▁from▁the▁entire▁country.▁in▁gash▁barka,▁deadly▁snakes▁like▁saw-scaled▁viper▁are▁common.▁puff▁adder▁and▁red▁spitting▁cobra▁are▁widespread▁and▁can▁be▁found▁even▁in▁the▁highlands.▁question▁:▁where▁in▁eritrea▁can▁puff▁adder▁and▁red▁spitting▁cobra▁be▁found?\n",
      "TRG : ▁widespread\n",
      "PRED : ▁highlands</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁city▁is▁considered▁highly▁innovative▁for▁a▁variety▁of▁reasons,▁including▁the▁presence▁of▁academia,▁access▁to▁venture▁capital,▁and▁the▁presence▁of▁many▁high-tech▁companies.▁the▁route▁128▁corridor▁and▁greater▁boston▁continue▁to▁be▁a▁major▁center▁for▁venture▁capital▁investment,▁and▁high▁technology▁remains▁an▁important▁sector.▁question▁:▁route▁128▁and▁greater▁boston▁are▁centers▁for▁what▁type▁of▁investment?\n",
      "TRG : ▁venture▁capital▁investment\n",
      "PRED : ▁venture▁capital</s>\n",
      "\n",
      "SRC : ▁context▁:▁by▁1847,▁the▁couple▁had▁found▁the▁palace▁too▁small▁for▁court▁life▁and▁their▁growing▁family,▁and▁consequently▁the▁new▁wing,▁designed▁by▁edward▁blore,▁was▁built▁by▁thomas▁cubitt,▁enclosing▁the▁central▁quadrangle.▁question▁:▁the▁new▁wing▁was▁built▁by▁whom?\n",
      "TRG : ▁thomas▁cubitt\n",
      "PRED : ▁thomas▁cubitt</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁city's▁population▁in▁2010▁was▁44%▁white▁(33.▁question▁:▁as▁of▁2010,▁what▁percentage▁made▁up▁white▁people▁in▁nyc?\n",
      "TRG : ▁44\n",
      "PRED : ▁44%</s>\n",
      "\n",
      "SRC : ▁context▁:▁in▁modern▁molecular▁biology▁and▁genetics,▁the▁genome▁is▁the▁genetic▁material▁of▁an▁organism.▁it▁consists▁of▁dna▁(or▁rna▁in▁rna▁viruses).▁the▁genome▁includes▁both▁the▁genes▁and▁the▁non-coding▁sequences▁of▁the▁dna/rna.▁question▁:▁what▁is▁the▁content▁of▁the▁human▁genome?\n",
      "TRG : ▁dna\n",
      "PRED : ▁both▁the▁genes▁and▁the▁non-coding▁sequences▁of▁the▁dna/rna</s>\n",
      "\n",
      "SRC : ▁context▁:▁lewis▁latimer,▁employed▁at▁the▁time▁by▁edison,▁developed▁an▁improved▁method▁of▁heat-treating▁carbon▁filaments▁which▁reduced▁breakage▁and▁allowed▁them▁to▁be▁molded▁into▁novel▁shapes,▁such▁as▁the▁characteristic▁\"m\"▁shape▁of▁maxim▁filaments.▁on▁17▁january▁1882,▁latimer▁received▁a▁patent▁for▁the▁\"process▁of▁manufacturing▁carbons\",▁an▁improved▁method▁for▁the▁production▁of▁light▁bulb▁filaments,▁which▁was▁purchased▁by▁the▁united▁states▁electric▁light▁company.▁question▁:▁when▁did▁latimer▁patent▁his▁\"process▁of▁manufacturing▁carbons\"?\n",
      "TRG : ▁17▁january▁1882\n",
      "PRED : ▁17▁january▁1882</s>\n",
      "\n",
      "SRC : ▁context▁:▁lateral-cut▁disc▁records▁were▁developed▁in▁the▁united▁states▁by▁emile▁berliner,▁who▁named▁his▁system▁the▁\"gramophone\",▁distinguishing▁it▁from▁edison's▁wax▁cylinder▁\"phonograph\"▁and▁columbia's▁wax▁cylinder▁\"graphophone\".▁question▁:▁where▁were▁lateral▁cut▁disc▁records▁developed?\n",
      "TRG : ▁united▁states\n",
      "PRED : ▁united▁states</s>\n",
      "\n",
      "SRC : ▁context▁:▁the▁category▁of▁native▁american▁applies▁to▁the▁diverse▁group▁of▁people▁who▁lived▁in▁north▁america▁before▁european▁settlement.▁during▁the▁u.s.▁government's▁westward▁expansion,▁native▁americans▁were▁displaced▁from▁their▁land▁which▁had▁been▁their▁home▁for▁centuries.▁instead,▁they▁were▁forced▁onto▁reservations▁which▁were▁far▁smaller▁and▁less▁productive.▁question▁:▁where▁were▁native▁americans▁forced▁to▁live▁after▁they▁lost▁their▁land?\n",
      "TRG : ▁reservations\n",
      "PRED : ▁reservations</s>\n",
      "\n",
      "SRC : ▁context▁:▁sirri▁amer▁was▁close▁to▁king▁farouk,▁and▁was▁nominated▁for▁the▁presidency▁of▁the▁officer's▁club—normally▁a▁ceremonial▁office—with▁the▁king's▁backing.▁question▁:▁who▁was▁nominated▁to▁the▁presidency▁of▁the▁officer's▁club?\n",
      "TRG : ▁sirri▁amer\n",
      "PRED : ▁sirri▁amer</s>\n",
      "\n",
      "SRC : ▁context▁:▁one▁of▁john's▁principal▁challenges▁was▁acquiring▁the▁large▁sums▁of▁money▁needed▁for▁his▁proposed▁campaigns▁to▁reclaim▁normandy.▁question▁:▁what▁was▁one▁of▁john's▁principal▁challenges?\n",
      "TRG : ▁acquiring▁the▁large▁sums▁of▁money▁needed\n",
      "PRED : ▁acquiring▁the▁large▁sums▁of▁money▁needed▁for▁his▁proposed▁campaigns▁to▁reclaim▁normandy</s>\n",
      "\n",
      "SRC : ▁context▁:▁there▁was▁also▁another▁government▁institution▁called▁imperial▁household▁department▁which▁was▁unique▁to▁the▁qing▁dynasty.▁it▁was▁established▁before▁the▁fall▁of▁the▁ming,▁but▁it▁became▁mature▁only▁after▁1661,▁following▁the▁death▁of▁the▁shunzhi▁emperor▁and▁the▁accession▁of▁his▁son,▁the▁kangxi▁emperor.▁question▁:▁which▁emperor▁followed▁shunzhi?\n",
      "TRG : ▁kangxi\n",
      "PRED : ▁kangxi▁emperor</s>\n",
      "\n",
      "SRC : ▁context▁:▁in▁2013,▁washington▁university▁received▁a▁record▁30,117▁applications▁for▁a▁freshman▁class▁of▁1,500▁with▁an▁acceptance▁rate▁of▁13.▁question▁:▁how▁many▁freshman▁class▁applications▁did▁washington▁university▁receive▁in▁2013?\n",
      "TRG : ▁30,117\n",
      "PRED : ▁30,117</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = random.sample(range(0, len(valid_data.examples)), 20)\n",
    "for i in idxs:\n",
    "    src = vars(valid_data.examples[i])['src']\n",
    "    trg = vars(valid_data.examples[i])['trg']\n",
    "    translation = translate_sentence2(src, model, device)\n",
    "\n",
    "    print(f\"SRC : {''.join(tokenizer.convert_ids_to_tokens(src))}\")\n",
    "    print(f\"TRG : {''.join(tokenizer.convert_ids_to_tokens(trg))}\")\n",
    "    print(f\"PRED : {''.join(tokenizer.convert_ids_to_tokens(translation))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_answer(context,query):\n",
    "    txt = 'context : ' + CONTEXT.lower() + ' question : ' + QUERY.lower()\n",
    "    txt_tokens = tokenizer.tokenize(txt)\n",
    "    txt_ids = tokenizer.convert_tokens_to_ids(txt_tokens)\n",
    "    pred = translate_sentence2(txt_ids, model, device)\n",
    "    pred_tokens = tokenizer.convert_ids_to_tokens(pred)\n",
    "    \n",
    "    return ''.join(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"harry is playing with his dog. the dog is twenty years old.\"\n",
    "QUERY = \"who is harry playing with ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁his▁dog</s>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_answer(CONTEXT,QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
